{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rpIx3C-vXXRv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "yfvk928-Xh_v",
    "outputId": "6a6bb930-8d25-4eb0-d65d-08e083398a13"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-19a22d2f-9bec-435d-b42c-4b61c7defe45\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19a22d2f-9bec-435d-b42c-4b61c7defe45')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-19a22d2f-9bec-435d-b42c-4b61c7defe45 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-19a22d2f-9bec-435d-b42c-4b61c7defe45');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width  species\n",
       "0             5.1          3.5           1.4          0.2        0\n",
       "1             4.9          3.0           1.4          0.2        0\n",
       "2             4.7          3.2           1.3          0.2        0\n",
       "3             4.6          3.1           1.5          0.2        0\n",
       "4             5.0          3.6           1.4          0.2        0\n",
       "..            ...          ...           ...          ...      ...\n",
       "145           6.7          3.0           5.2          2.3        2\n",
       "146           6.3          2.5           5.0          1.9        2\n",
       "147           6.5          3.0           5.2          2.0        2\n",
       "148           6.2          3.4           5.4          2.3        2\n",
       "149           5.9          3.0           5.1          1.8        2\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataset = pd.read_csv('/content/IRIS.csv')\n",
    "iris_dataset['species'] = LabelEncoder().fit_transform(iris_dataset['species'])\n",
    "iris_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UU6p4a-vX-Hr"
   },
   "outputs": [],
   "source": [
    "class Node():\n",
    "  def __init__(self, feature_index = None, threshold = None, left = None, right = None, info_gain = None, value = None):\n",
    "    # for decision nodes (internal nodes)\n",
    "    self.feature_index = feature_index\n",
    "    self.threshold = threshold\n",
    "    self.left = left\n",
    "    self.right = right\n",
    "    self.info_gain = info_gain\n",
    "\n",
    "    # for leaf node\n",
    "    self.value = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "TRWC1U_1YzL8"
   },
   "outputs": [],
   "source": [
    "class DecisionTreeClassifierFromScratch():\n",
    "  def __init__(self, min_samples_split = 2, max_depth = 2, max_features_per_split = 3, criterion = 'gini'):\n",
    "    self.root = None\n",
    "    self.max_features_per_split = max_features_per_split\n",
    "    self.criterion = criterion\n",
    "\n",
    "    # set the stopping conditions\n",
    "    self.min_samples_split = min_samples_split\n",
    "    self.max_depth = max_depth\n",
    "    \n",
    "  def gini_index(self, y):\n",
    "    class_labels = np.unique(y)\n",
    "    gini = 0\n",
    "    for cls in class_labels:\n",
    "      p_cls = len(y[y == cls])/len(y)\n",
    "      gini += (p_cls ** 2)\n",
    "    return 1 - gini\n",
    "\n",
    "  def entropy(self, y):\n",
    "    class_labels = np.unique(y)\n",
    "    entropy = 0 \n",
    "    for cls in class_labels:\n",
    "      p_cls = len(y[y == cls])/len(y)\n",
    "      entropy += -p_cls * np.log2(p_cls)\n",
    "    return entropy\n",
    "\n",
    "  def information_gain(self, parent, l_child, r_child, mode):\n",
    "    ## parent: the list of ground truth labels for all the points in the region of the parent node\n",
    "    ## l_child : the list of ground truth labels for all the points in the region l_child\n",
    "    weight_l = len(l_child)/len(parent)\n",
    "    weight_r = len(r_child)/len(parent)\n",
    "\n",
    "    if mode == 'gini':\n",
    "      gain = self.gini_index(parent) - ((weight_l * self.gini_index(l_child)) + (weight_r * self.gini_index(r_child)))\n",
    "    else:\n",
    "      gain = self.entropy(parent) - ((weight_l * self.entropy(l_child)) + (weight_r * self.entropy(r_child)))\n",
    "    return gain\n",
    "\n",
    "  def split(self, dataset, feature_index, threshold):\n",
    "    dataset_left = np.array([row for row in dataset if row[feature_index] <= threshold])\n",
    "    dataset_right = np.array([row for row in dataset if row[feature_index] > threshold])\n",
    "    return dataset_left, dataset_right\n",
    "\n",
    "  def get_best_split(self, dataset, num_samples, num_features, max_features_per_split, mode):\n",
    "    # define a dictionary to store the best split\n",
    "    best_split = {}\n",
    "    max_info_gain = -float(\"inf\")\n",
    "\n",
    "    # loop over a random sample of the features\n",
    "    random_features_indices = np.random.choice(num_features, size = max_features_per_split, replace = False)\n",
    "    for feature_index in random_features_indices:\n",
    "      feature_values = dataset[ :, feature_index]\n",
    "      possible_thresholds = np.unique(feature_values)\n",
    "\n",
    "      # loop over all possible split values (thresholds) for the current feature\n",
    "      for threshold in possible_thresholds:\n",
    "        dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
    "        # making sure that the current split has left and right datasets \n",
    "        if len(dataset_left) > 0 and len(dataset_right) > 0:\n",
    "          y_parent, y_left_child, y_right_child = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
    "          curr_info_gain = self.information_gain(y_parent, y_left_child, y_right_child, mode = mode)\n",
    "          if curr_info_gain > max_info_gain:\n",
    "            best_split['feature_index'] = feature_index\n",
    "            best_split['threshold'] = threshold\n",
    "            best_split['dataset_left'] = dataset_left\n",
    "            best_split['dataset_right'] = dataset_right\n",
    "            best_split['info_gain'] = curr_info_gain\n",
    "            max_info_gain = curr_info_gain\n",
    "    return best_split\n",
    "\n",
    "  def calculate_leaf_value(self, Y):\n",
    "    Y = list(Y)\n",
    "    return max(Y, key = Y.count)\n",
    "\n",
    "  def build_tree(self, dataset, curr_depth = 0):\n",
    "    # recursive function to build the tree\n",
    "    X, Y = dataset[:, :-1], dataset[:, -1]\n",
    "    num_samples, num_features = np.shape(X)\n",
    "    # we will split until the stopping coditions are met\n",
    "    if num_samples >= self.min_samples_split and curr_depth <= self.max_depth:\n",
    "      # getting the best split; it returns a dictionary\n",
    "      best_split = self.get_best_split(dataset, num_samples, num_features, self.max_features_per_split, self.criterion)\n",
    "      # check if the information gain after the best split is positive\n",
    "      if best_split['info_gain'] > 0:\n",
    "        left_subtree = self.build_tree(best_split['dataset_left'], curr_depth + 1)\n",
    "        right_subtree = self.build_tree(best_split['dataset_right'], curr_depth + 1)\n",
    "        return Node(feature_index = best_split['feature_index'], threshold = best_split['threshold'], \n",
    "                    left = left_subtree, right = right_subtree, info_gain = best_split['info_gain'], value = None)\n",
    "        \n",
    "    # compute the leaf node only if we are out of the stopping condition\n",
    "    leaf_value = self.calculate_leaf_value(Y) \n",
    "    # return leaf node\n",
    "    return Node(value = leaf_value)\n",
    "\n",
    "  def fit(self, X, Y):\n",
    "    dataset = np.concatenate((X, Y), axis = 1)\n",
    "    self.root = self.build_tree(dataset)\n",
    "\n",
    "  def make_prediction(self, x, tree):\n",
    "    if tree.value != None: \n",
    "      return tree.value\n",
    "    feature_val = x[tree.feature_index]\n",
    "    if feature_val <= tree.threshold:\n",
    "      return self.make_prediction(x, tree.left)\n",
    "    else:\n",
    "      return self.make_prediction(x, tree.right)\n",
    "\n",
    "  def predict(self, X):\n",
    "    predictions = [self.make_prediction(x, self.root) for x in X]\n",
    "    return predictions\n",
    "\n",
    "  def print_tree(self, tree=None, indent=\" \"):\n",
    "        ''' function to print the tree '''\n",
    "        \n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "\n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "\n",
    "        else:\n",
    "            print(\"X_\"+str(tree.feature_index), \"<=\", tree.threshold, \"?\", tree.info_gain)\n",
    "            print(\"%sleft:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.left, indent + indent)\n",
    "            print(\"%sright:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.right, indent + indent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "oB4_Gcd6lS_X"
   },
   "outputs": [],
   "source": [
    "X = iris_dataset.iloc[:, :-1].values\n",
    "Y = iris_dataset.iloc[:, -1].values.reshape(-1,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "Y-X475CclclA"
   },
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifierFromScratch(min_samples_split = 3, max_depth = 3, max_features_per_split = 2, criterion= 'gini')\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Toi9AozLl4UT",
    "outputId": "2163e248-4e65-4172-f918-80182032472f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = classifier.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "diJv71z-mYbp",
    "outputId": "8901e8f0-b2cb-404d-a402-073bd7d23c74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_2 <= 1.9 ? 0.33741385372714494\n",
      " left:0.0\n",
      " right:X_3 <= 1.5 ? 0.427106638180289\n",
      "  left:X_1 <= 2.6 ? 0.0023743569449938967\n",
      "    left:X_2 <= 4.9 ? 0.13265306122448983\n",
      "        left:1.0\n",
      "        right:2.0\n",
      "    right:1.0\n",
      "  right:X_3 <= 1.7 ? 0.012784787668159228\n",
      "    left:X_2 <= 4.5 ? 0.1111111111111111\n",
      "        left:2.0\n",
      "        right:1.0\n",
      "    right:X_2 <= 4.8 ? 0.016158818097876115\n",
      "        left:2.0\n",
      "        right:2.0\n"
     ]
    }
   ],
   "source": [
    "classifier.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "xYGEucFciqmR"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(criterion = 'gini',splitter = 'best', max_depth = 3, min_samples_split = 3, max_features = 2)\n",
    "clf.fit(X_train, Y_train)\n",
    "DT_sklearn_preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H8i0iuf5i6tZ",
    "outputId": "fc80e30d-9b78-4e9a-a916-5f92025ba307"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test, DT_sklearn_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gI2jI4Njuq8n"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "91zsDDbYutil"
   },
   "outputs": [],
   "source": [
    "def bootstrap_sample(X, y, bag_size = 100):\n",
    "  tot_num_of_observations = X.shape[0]\n",
    "  random_indices = np.random.choice(tot_num_of_observations, size = bag_size, replace = True)\n",
    "  return X[random_indices], y[random_indices]\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def most_common_label(y):\n",
    "  counter = Counter(y)\n",
    "  most_common = counter.most_common(1)[0][0]\n",
    "  return most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "dhAA8xjJvlD6"
   },
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "  def __init__(self, min_samples_split = 2, max_depth = 2, max_features_per_split = 3, criterion = 'gini', n_trees = 20, sample_size_per_tree = 100):\n",
    "    self.min_samples_split = min_samples_split\n",
    "    self.max_depth = max_depth\n",
    "    self.max_features_per_split = max_features_per_split\n",
    "    self.criterion = criterion\n",
    "    self.n_trees = n_trees\n",
    "    self.sample_size_per_tree = sample_size_per_tree\n",
    "    # Defining a list of trees\n",
    "    self.trees = []\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    self.trees = []\n",
    "    for _ in range(self.n_trees):\n",
    "      tree = DecisionTreeClassifierFromScratch(min_samples_split = self.min_samples_split, max_depth = self.max_depth, \n",
    "                                    max_features_per_split = self.max_features_per_split, criterion = self.criterion)\n",
    "      X_sample, y_sample = bootstrap_sample(X, y, bag_size = self.sample_size_per_tree)\n",
    "      tree.fit(X_sample, y_sample)\n",
    "      self.trees.append(tree)\n",
    "\n",
    "  def predict(self, X):\n",
    "    tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
    "    ## if you have 4 data points for 3 trees, the output will be as follows:\n",
    "    ## [ T1,  T2,  T3]\n",
    "    ## [1111 0000 1111]\n",
    "    ## however, we would like the output to be the predictions for each data-point using the 3 trees\n",
    "    ## [ p1, p2, p3, p4]\n",
    "    ## [101 101 101 101]\n",
    "    tree_preds = np.swapaxes(tree_preds, 0, 1)\n",
    "    y_pred = [most_common_label(tree_pred) for tree_pred in tree_preds]\n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "DKBtAIgux-rf"
   },
   "outputs": [],
   "source": [
    "RF_classifier = RandomForest(min_samples_split = 3, max_depth = 3, max_features_per_split = 2, criterion= 'gini', n_trees = 50, sample_size_per_tree = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "Mrebjc2uyG6u"
   },
   "outputs": [],
   "source": [
    "RF_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MfeXZ9msyKN-",
    "outputId": "e812ad54-1134-4ccd-ed4e-32cd0f07fa75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_preds_RF = RF_classifier.predict(X_test)\n",
    "accuracy_score(Y_test, Y_preds_RF)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Random_Forest_Lab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
